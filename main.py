import sys
print("PYTHON VERSION:", sys.version)

from fastapi import FastAPI
from fastapi.responses import HTMLResponse

app = FastAPI()

@app.get("/", response_class=HTMLResponse)
def home():
    return """
    <h1>DaVinci OTIO Beat Cutter</h1>
    <p>Server is running ‚úÖ</p>
    """

import argparse
from pathlib import Path
import numpy as np
import librosa
# --- scipy/librosa compatibility patch ---
import scipy.signal as _sig
if not hasattr(_sig, "hann"):
    from scipy.signal.windows import hann as _hann
    _sig.hann = _hann
# ---------------------------------------

import opentimelineio as otio


def detect_beats(audio_path: str, sr: int = 22050, start_offset: float = 0.0):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ –≤—Ä–µ–º–µ–Ω–∏ –±–∏—Ç–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    y, sr = librosa.load(audio_path, sr=sr, mono=True)
    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr, units="frames")
    beat_times = librosa.frames_to_time(beat_frames, sr=sr)
    beat_times = beat_times + float(start_offset)
    # –£–±–∏—Ä–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ/–¥—É–±–ª–∏
    beat_times = beat_times[beat_times > 0]
    beat_times = np.unique(np.round(beat_times, 4))
    return beat_times.tolist(), float(librosa.get_duration(y=y, sr=sr))


def build_cut_times(beat_times, music_duration, min_cut, max_cut):
    """
    –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ —Ä–µ–∑–∫–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö), –∏—Å–ø–æ–ª—å–∑—É—è –±–∏—Ç—ã.
    –ü—Ä–∞–≤–∏–ª–æ:
      - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ –±–∏—Ç—ã (< min_cut)
      - –µ—Å–ª–∏ –º–µ–∂–¥—É —Ä–µ–∑–∫–∞–º–∏ –æ—á–µ–Ω—å –¥–æ–ª–≥–æ (> max_cut), –≤—Å—ë —Ä–∞–≤–Ω–æ —Ä–µ–∂–µ–º –Ω–∞ –±–ª–∏–∂–∞–π—à–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–º –±–∏—Ç–µ (–µ—Å–ª–∏ –µ—Å—Ç—å),
        –∏–Ω–∞—á–µ —Ä–µ–∂–µ–º –ø–æ max_cut (—Ä–µ–¥–∫–∏–π –∫–µ–π—Å)
    """
    cuts = [0.0]
    last = 0.0

    for t in beat_times:
        if t <= last:
            continue
        dt = t - last
        if dt < min_cut:
            continue

        if dt > max_cut:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à–∏–π –±–∏—Ç <= last + max_cut
            target = last + max_cut
            candidates = [b for b in beat_times if last < b <= target]
            if candidates:
                chosen = candidates[-1]
                cuts.append(chosen)
                last = chosen
            else:
                # –∫—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π ‚Äî —Ä–µ–∂–µ–º –Ω–µ –ø–æ –±–∏—Ç—É
                cuts.append(target)
                last = target
        else:
            cuts.append(t)
            last = t

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ ‚Äî –∫–æ–Ω–µ—Ü –º—É–∑—ã–∫–∏ (–º–æ–∂–Ω–æ –Ω–µ —Ä–µ–∑–∞—Ç—å —Å—Ç—Ä–æ–≥–æ –ø–æ –±–∏—Ç—É)
    if music_duration > cuts[-1] + 0.01:
        cuts.append(music_duration)

    # –£–±–µ—Ä—ë–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ö–≤–æ—Å—Ç—ã
    cleaned = [cuts[0]]
    for c in cuts[1:]:
        if c - cleaned[-1] >= min_cut:
            cleaned.append(c)
    return cleaned


def find_first_timeline_and_video_track(timeline: otio.schema.Timeline):
    video_tracks = [t for t in timeline.tracks if t.kind == otio.schema.TrackKind.Video]
    if not video_tracks:
        raise RuntimeError("–í OTIO –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ–¥–æ—Ä–æ–∂–µ–∫ (TrackKind.Video).")
    return video_tracks[0]


def collect_clips_in_order(video_track: otio.schema.Track):
    clips = []
    for item in video_track:
        if isinstance(item, otio.schema.Clip):
            clips.append(item)
    if not clips:
        raise RuntimeError("–ù–∞ –≤–∏–¥–µ–æ–¥–æ—Ä–æ–∂–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∫–ª–∏–ø–æ–≤ (otio.schema.Clip).")
    return clips


def seconds_to_rational_time(sec: float, rate: float) -> otio.opentime.RationalTime:
    return otio.opentime.RationalTime(sec * rate, rate)


def make_timerange(start_sec: float, dur_sec: float, rate: float) -> otio.opentime.TimeRange:
    return otio.opentime.TimeRange(
        start_time=seconds_to_rational_time(start_sec, rate),
        duration=seconds_to_rational_time(dur_sec, rate)
    )


def get_source_range_or_default(clip: otio.schema.Clip, rate: float):
    # –í OTIO —É –∫–ª–∏–ø–∞ –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å source_range ‚Äî —Ç–æ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ "–≤—Å—ë".
    # –ù–æ "–≤—Å—ë" –±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ —É–∑–Ω–∞—Ç—å. –í —ç—Ç–æ–º MVP –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ source_range –µ—Å—Ç—å.
    if clip.source_range is None:
        raise RuntimeError(
            f"–ö–ª–∏–ø '{clip.name}' –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç source_range. "
            "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π OTIO –∏–∑ Resolve —Ç–∞–∫, —á—Ç–æ–±—ã –¥–∏–∞–ø–∞–∑–æ–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è–ª–∏—Å—å."
        )
    return clip.source_range


def rebuild_timeline(input_otio: str, music_mp3: str, output_otio: str,
                     fps: float, min_cut: float, max_cut: float, beat_offset: float):
    timeline = otio.adapters.read_from_file(input_otio)
    if not isinstance(timeline, otio.schema.Timeline):
        raise RuntimeError("OTIO-—Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è Timeline.")

    video_track_in = find_first_timeline_and_video_track(timeline)
    source_clips = collect_clips_in_order(video_track_in)

    beat_times, music_duration = detect_beats(music_mp3, start_offset=beat_offset)
    cuts = build_cut_times(beat_times, music_duration, min_cut=min_cut, max_cut=max_cut)

    # –°–µ–≥–º–µ–Ω—Ç—ã, –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —Ä–µ–∑–∞—Ç—å –≤–∏–¥–µ–æ
    segments = [(cuts[i], cuts[i+1]) for i in range(len(cuts)-1)]
    segment_durations = [b - a for a, b in segments]

    out_tl = otio.schema.Timeline(name=f"{timeline.name}_beatcut")
    out_tracks = otio.schema.Stack()

    out_video = otio.schema.Track(name="V1", kind=otio.schema.TrackKind.Video)
    out_audio = otio.schema.Track(name="A1_music", kind=otio.schema.TrackKind.Audio)

    # –ê—É–¥–∏–æ –∫–ª–∏–ø (–º—É–∑—ã–∫–∞)
    music_ref = otio.schema.ExternalReference(target_url=str(Path(music_mp3).resolve().as_posix()))
    music_clip = otio.schema.Clip(name=Path(music_mp3).stem, media_reference=music_ref)
    music_clip.source_range = make_timerange(0.0, music_duration, fps)
    out_audio.append(music_clip)

        # –ù–∞—Ä–µ–∑–∫–∞ –≤–∏–¥–µ–æ (–∫–∞–∂–¥—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–ª–∏–ø –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û 1 —Ä–∞–∑)
    src_i = 0  # –∏–Ω–¥–µ–∫—Å –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–ª–∏–ø–∞

    for dur in segment_durations:
        if src_i >= len(source_clips):
            break

        remaining = float(dur)

        # –≠—Ç–æ—Ç —Å–µ–≥–º–µ–Ω—Ç –º–æ–∂–µ—Ç –∑–∞–ø–æ–ª–Ω–∏—Ç—å—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–ª–∏–ø–∞–º–∏ (–µ—Å–ª–∏ –æ–Ω–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ),
        # –Ω–æ –ö–ê–ñ–î–´–ô –∫–ª–∏–ø –±–µ—Ä—ë—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑: –≤–∑—è–ª–∏ –∫—É—Å–æ–∫ -> –æ—Å—Ç–∞—Ç–æ–∫ –∫–ª–∏–ø–∞ –≤—ã–∫–∏–Ω—É–ª–∏ -> —Å–ª–µ–¥—É—é—â–∏–π –∫–ª–∏–ø.
        while remaining > 1e-6 and src_i < len(source_clips):
            src_clip = source_clips[src_i]
            src_i += 1  # –í–ê–ñ–ù–û: —Å—Ä–∞–∑—É –¥–≤–∏–≥–∞–µ–º—Å—è –¥–∞–ª—å—à–µ, –∫–ª–∏–ø –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º

            sr = get_source_range_or_default(src_clip, fps)
            sr_start = sr.start_time.to_seconds()
            sr_dur = sr.duration.to_seconds()

            if sr_dur <= 1e-6:
                continue

            take = min(sr_dur, remaining)

            new_clip = otio.schema.Clip(
                name=src_clip.name,
                media_reference=src_clip.media_reference
            )

            # –ë–µ—Ä—ë–º –¢–û–õ–¨–ö–û –Ω–∞—á–∞–ª–æ –∫–ª–∏–ø–∞ (–µ–≥–æ source_range start) –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å take.
            # –û—Å—Ç–∞–≤—à—É—é—Å—è —á–∞—Å—Ç—å –∫–ª–∏–ø–∞ –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º.
            new_clip.source_range = make_timerange(
                start_sec=sr_start,
                dur_sec=take,
                rate=fps
            )

            out_video.append(new_clip)
            remaining -= take


            # –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –∫–ª–∏–ø –∑–∞–∫–æ–Ω—á–∏–ª—Å—è ‚Äî –∏–¥—ë–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É
            if src_pos_sec >= sr_dur - 1e-6:
                src_i += 1
                src_pos_sec = 0.0

    out_tracks.append(out_video)
    out_tracks.append(out_audio)
    out_tl.tracks = out_tracks

    otio.adapters.write_to_file(out_tl, output_otio)


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--timeline", required=True, help="input .otio from DaVinci")
    ap.add_argument("--music", required=True, help="music .mp3")
    ap.add_argument("--out", default="output.otio", help="output .otio")
    ap.add_argument("--fps", type=float, default=25.0, help="timeline fps (default: 25)")
    ap.add_argument("--min_cut", type=float, default=0.30, help="min segment duration seconds")
    ap.add_argument("--max_cut", type=float, default=1.20, help="max segment duration seconds")
    ap.add_argument("--beat_offset", type=float, default=0.0, help="shift beats in seconds (+/-)")
    args = ap.parse_args()

    rebuild_timeline(
        input_otio=args.timeline,
        music_mp3=args.music,
        output_otio=args.out,
        fps=args.fps,
        min_cut=args.min_cut,
        max_cut=args.max_cut,
        beat_offset=args.beat_offset
    )
    print(f"Done. Saved: {args.out}")


if __name__ == "__main__":
    main()
# üî• –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
del timeline, out_tl, out_tracks, out_video, out_audio
gc.collect()
